---
layout: archive
title: "Projet super résolution"
permalink: /super_resolution/
author_profile: true
---

<div style="text-align: justify"> 
During my last year of my master's degree, I worked on different methods of color and style transfer in collaboration with Thomas Lemetayer. We tested algorithms from [Reinhard et al. 2001], [Pitié and Kokaram 2007] and [Gatys et al. 2015]. 
Style and color transfer consists in transferring characteristics of a style image such as its color, distribution or textures to an image whose forms and content are retained.
</div>

<div style="text-align: justify"> 
First, we worked on the algorithm of [Reinhard et al. 2001]. This can be described as follows: 
Calculate the mean and standard deviation for the content image and the style image
Transfer the mean and standard deviation of the style image to the content image
This method is very fast and gives good results when we have Gaussian color distributions in the images. Moreover, it is possible to work in different color spaces such as Lαβ to have very uncorrelated channels and have better distributions.

<div style="text-align:center"><img src="https://raw.githubusercontent.com/iribis/iribis.github.io/master/images/Reinhard.jpg?raw=true" height="70%" width="70%"style="transform:rotate(0deg);"/></div>
</div>

<div style="text-align: justify"> 
We have proposed a method to extend this method to HDR (Hight Dynamic Range) images based on the tone mapping of [Reinhard and Devlin 2005] and giving better results than applying the color transfer to tone mapped images.

<div style="text-align:center"><img src="https://raw.githubusercontent.com/iribis/iribis.github.io/master/images/hdrColorTransfert.jpg?raw=true" height="60%" width="60%"style="transform:rotate(0deg);"/></div>
</div> 

<div style="text-align: justify"> 
Then, we worked on the algorithm of [Pitié and Kokaram 2007] based on colorimetric distribution matching. It is an iterative algorithm giving very good results on natural scenes.

<div style="text-align:center"><img src="https://raw.githubusercontent.com/iribis/iribis.github.io/master/images/pitie.jpg?raw=true" height="100%" width="100%"style="transform:rotate(0deg);"/></div>
</div>

<div style="text-align: justify"> 
We have also worked on extending color transfer to video and multi-style.  Indeed, it is possible to use several style images to generate a single resulting image.By applying images from different seasons we can then give the impression of time passing on a single image, this effect is called time hallucination.

<div style="text-align:center"><img src="https://raw.githubusercontent.com/iribis/iribis.github.io/master/images/Degrade.png?raw=true" height="80%" width="80%"style="transform:rotate(0deg);"/></div>
</div>

<div style="text-align: justify"> 
Finally, we worked on style transfer and in particular on the machine learning approach of [Gatys et al. 2015] which is available on the deepart.io website.

<div style="text-align:center"><img src="https://raw.githubusercontent.com/iribis/iribis.github.io/master/images/deepArt.jpg?raw=true" height="70%" width="70%"style="transform:rotate(0deg);"/></div>
</div>

<div style="text-align: justify"> 
One of the applications of style transfer that we have studied is texture synthesis. To do this, we apply style transfer to a noise image and obtain a random image with the characteristics of the reference texture.

<div style="text-align:center"><img src="https://raw.githubusercontent.com/iribis/iribis.github.io/master/images/textureSynthesis.jpg?raw=true" height="70%" width="70%"style="transform:rotate(0deg);"/></div>
</div>
